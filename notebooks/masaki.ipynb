{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "from tensorflow_docs.vis import embed\n",
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Import matplotlib libraries\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib.collections import LineCollection\n",
    "import matplotlib.patches as patches\n",
    "\n",
    "# Some modules to display an animation using imageio.\n",
    "import imageio\n",
    "from IPython.display import HTML, display\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Initialization\n",
    "model_name = \"movenet_lightning\"\n",
    "# module = hub.load(\"https://tfhub.dev/google/movenet/singlepose/lightning/4\")\n",
    "# input_size = 192\n",
    "model = module.signatures['serving_default']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose image file and preprocess\n",
    "\n",
    "image_path = \"../clean_data/clean_dd_train/00000320.jpg\"\n",
    "image = tf.io.read_file(image_path)\n",
    "image = tf.image.decode_jpeg(image)\n",
    "\n",
    "# Resize and pad the image to keep the aspect ratio and fit the expected size.\n",
    "input_image = tf.expand_dims(image, axis=0)\n",
    "input_image = tf.image.resize_with_pad(input_image, input_size, input_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detect landmarks on image\n",
    "model = module.signatures[\"serving_default\"]\n",
    "input_image = tf.cast(input_image, dtype=tf.int32)\n",
    "input_image = input_image[..., :3]\n",
    "outputs = model(input_image)\n",
    "\n",
    "# 1D array of xyz coordinates. X1, Y1, Z1, X2, ... , Yn, Zn format\n",
    "xyz = outputs[\"output_0\"].numpy().reshape(51).tolist()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper method for drawing landmarks\n",
    "def draw_prediction_on_image(\n",
    "    image, keypoints_with_scores, crop_region=None, close_figure=False,\n",
    "    output_image_height=None):\n",
    "  \"\"\"Draws the keypoint predictions on image.\n",
    "\n",
    "  Args:\n",
    "    image: A numpy array with shape [height, width, channel] representing the\n",
    "      pixel values of the input image.\n",
    "    keypoints_with_scores: A numpy array with shape [1, 1, 17, 3] representing\n",
    "      the keypoint coordinates and scores returned from the MoveNet model.\n",
    "    crop_region: A dictionary that defines the coordinates of the bounding box\n",
    "      of the crop region in normalized coordinates (see the init_crop_region\n",
    "      function below for more detail). If provided, this function will also\n",
    "      draw the bounding box on the image.\n",
    "    output_image_height: An integer indicating the height of the output image.\n",
    "      Note that the image aspect ratio will be the same as the input image.\n",
    "\n",
    "  Returns:\n",
    "    A numpy array with shape [out_height, out_width, channel] representing the\n",
    "    image overlaid with keypoint predictions.\n",
    "  \"\"\"\n",
    "  height, width, channel = image.shape\n",
    "  aspect_ratio = float(width) / height\n",
    "  fig, ax = plt.subplots(figsize=(12 * aspect_ratio, 12))\n",
    "  # To remove the huge white borders\n",
    "  fig.tight_layout(pad=0)\n",
    "  ax.margins(0)\n",
    "  ax.set_yticklabels([])\n",
    "  ax.set_xticklabels([])\n",
    "  plt.axis('off')\n",
    "\n",
    "  im = ax.imshow(image)\n",
    "  line_segments = LineCollection([], linewidths=(4), linestyle='solid')\n",
    "  ax.add_collection(line_segments)\n",
    "  # Turn off tick labels\n",
    "  scat = ax.scatter([], [], s=60, color='#FF1493', zorder=3)\n",
    "\n",
    "  (keypoint_locs, keypoint_edges,\n",
    "   edge_colors) = _keypoints_and_edges_for_display(\n",
    "       keypoints_with_scores, height, width)\n",
    "\n",
    "  line_segments.set_segments(keypoint_edges)\n",
    "  line_segments.set_color(edge_colors)\n",
    "  if keypoint_edges.shape[0]:\n",
    "    line_segments.set_segments(keypoint_edges)\n",
    "    line_segments.set_color(edge_colors)\n",
    "  if keypoint_locs.shape[0]:\n",
    "    scat.set_offsets(keypoint_locs)\n",
    "\n",
    "  if crop_region is not None:\n",
    "    xmin = max(crop_region['x_min'] * width, 0.0)\n",
    "    ymin = max(crop_region['y_min'] * height, 0.0)\n",
    "    rec_width = min(crop_region['x_max'], 0.99) * width - xmin\n",
    "    rec_height = min(crop_region['y_max'], 0.99) * height - ymin\n",
    "    rect = patches.Rectangle(\n",
    "        (xmin,ymin),rec_width,rec_height,\n",
    "        linewidth=1,edgecolor='b',facecolor='none')\n",
    "    ax.add_patch(rect)\n",
    "\n",
    "  fig.canvas.draw()\n",
    "  image_from_plot = np.frombuffer(fig.canvas.tostring_rgb(), dtype=np.uint8)\n",
    "  image_from_plot = image_from_plot.reshape(\n",
    "      fig.canvas.get_width_height()[::-1] + (3,))\n",
    "  plt.close(fig)\n",
    "  if output_image_height is not None:\n",
    "    output_image_width = int(output_image_height / height * width)\n",
    "    image_from_plot = cv2.resize(\n",
    "        image_from_plot, dsize=(output_image_width, output_image_height),\n",
    "         interpolation=cv2.INTER_CUBIC)\n",
    "  return image_from_plot\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get list of image file names in given directory\n",
    "dir_path_train_dd = \"../clean_data/clean_dd_train\"\n",
    "file_names = []\n",
    "for entry in os.listdir(dir_path_train_dd):\n",
    "    file_names.append(entry)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../clean_data/clean_dd_train/00000372.jpg\n",
      "../clean_data/clean_dd_train/00000414.jpg\n",
      "../clean_data/clean_dd_train/00000158.jpg\n",
      "../clean_data/clean_dd_train/00000164.jpg\n",
      "../clean_data/clean_dd_train/00000170.jpg\n",
      "../clean_data/clean_dd_train/00000366.png\n",
      "../clean_data/clean_dd_train/00000206.jpg\n",
      "../clean_data/clean_dd_train/00000213.jpg\n",
      "../clean_data/clean_dd_train/00000165.jpg\n",
      "../clean_data/clean_dd_train/00000159.jpg\n",
      "../clean_data/clean_dd_train/00000198.png\n",
      "../clean_data/clean_dd_train/00000417.jpg\n",
      "../clean_data/clean_dd_train/00000403.jpg\n",
      "../clean_data/clean_dd_train/00000173.jpg\n",
      "../clean_data/clean_dd_train/00000239.jpg\n",
      "../clean_data/clean_dd_train/00000210.jpg\n",
      "../clean_data/clean_dd_train/00000204.jpg\n",
      "../clean_data/clean_dd_train/00000238.jpg\n",
      "../clean_data/clean_dd_train/00000199.jpg\n",
      "../clean_data/clean_dd_train/00000166.jpg\n",
      "../clean_data/clean_dd_train/00000172.jpg\n",
      "../clean_data/clean_dd_train/00000416.jpg\n",
      "../clean_data/clean_dd_train/00000358.jpg\n",
      "../clean_data/clean_dd_train/00000412.jpg\n",
      "../clean_data/clean_dd_train/00000406.jpg\n",
      "../clean_data/clean_dd_train/00000360.jpg\n",
      "../clean_data/clean_dd_train/00000176.jpg\n",
      "../clean_data/clean_dd_train/00000162.jpg\n",
      "../clean_data/clean_dd_train/00000189.jpg\n",
      "../clean_data/clean_dd_train/00000228.png\n",
      "../clean_data/clean_dd_train/00000200.jpg\n",
      "../clean_data/clean_dd_train/00000214.jpg\n",
      "../clean_data/clean_dd_train/00000229.jpg\n",
      "../clean_data/clean_dd_train/00000201.jpg\n",
      "../clean_data/clean_dd_train/00000163.jpg\n",
      "../clean_data/clean_dd_train/00000375.jpg\n",
      "../clean_data/clean_dd_train/00000377.jpg\n",
      "../clean_data/clean_dd_train/00000161.jpg\n",
      "../clean_data/clean_dd_train/00000175.jpg\n",
      "../clean_data/clean_dd_train/00000217.jpg\n",
      "../clean_data/clean_dd_train/00000216.jpg\n",
      "../clean_data/clean_dd_train/00000160.jpg\n",
      "../clean_data/clean_dd_train/00000376.jpg\n",
      "../clean_data/clean_dd_train/00000404.jpg\n",
      "../clean_data/clean_dd_train/00000264.jpg\n",
      "../clean_data/clean_dd_train/00000270.jpg\n",
      "../clean_data/clean_dd_train/00000258.jpg\n",
      "../clean_data/clean_dd_train/00000310.png\n",
      "../clean_data/clean_dd_train/00000304.jpg\n",
      "../clean_data/clean_dd_train/00000338.jpg\n",
      "../clean_data/clean_dd_train/00000312.jpg\n",
      "../clean_data/clean_dd_train/00000306.jpg\n",
      "../clean_data/clean_dd_train/00000138.jpg\n",
      "../clean_data/clean_dd_train/00000266.jpg\n",
      "../clean_data/clean_dd_train/00000272.jpg\n",
      "../clean_data/clean_dd_train/00000299.jpg\n",
      "../clean_data/clean_dd_train/00000139.jpg\n",
      "../clean_data/clean_dd_train/00000303.jpg\n",
      "../clean_data/clean_dd_train/00000129.jpg\n",
      "../clean_data/clean_dd_train/00000263.jpg\n",
      "../clean_data/clean_dd_train/00000288.jpg\n",
      "../clean_data/clean_dd_train/00000289.jpg\n",
      "../clean_data/clean_dd_train/00000276.jpg\n",
      "../clean_data/clean_dd_train/00000128.jpg\n",
      "../clean_data/clean_dd_train/00000316.jpg\n",
      "../clean_data/clean_dd_train/00000300.jpg\n",
      "../clean_data/clean_dd_train/00000314.jpg\n",
      "../clean_data/clean_dd_train/00000328.jpg\n",
      "../clean_data/clean_dd_train/00000248.jpg\n",
      "../clean_data/clean_dd_train/00000329.jpg\n",
      "../clean_data/clean_dd_train/00000315.jpg\n",
      "../clean_data/clean_dd_train/00000301.jpg\n",
      "../clean_data/clean_dd_train/00000324.jpg\n",
      "../clean_data/clean_dd_train/00000330.jpg\n",
      "../clean_data/clean_dd_train/00000132.png\n",
      "../clean_data/clean_dd_train/00000287.png\n",
      "../clean_data/clean_dd_train/00000278.jpg\n",
      "../clean_data/clean_dd_train/00000250.jpg\n",
      "../clean_data/clean_dd_train/00000244.jpg\n",
      "../clean_data/clean_dd_train/00000293.jpg\n",
      "../clean_data/clean_dd_train/00000286.jpg\n",
      "../clean_data/clean_dd_train/00000292.jpg\n",
      "../clean_data/clean_dd_train/00000251.jpg\n",
      "../clean_data/clean_dd_train/00000279.jpg\n",
      "../clean_data/clean_dd_train/00000245.png\n",
      "../clean_data/clean_dd_train/00000133.jpg\n",
      "../clean_data/clean_dd_train/00000325.jpg\n",
      "../clean_data/clean_dd_train/00000319.jpg\n",
      "../clean_data/clean_dd_train/00000290.png\n",
      "../clean_data/clean_dd_train/00000247.jpg\n",
      "../clean_data/clean_dd_train/00000291.jpg\n",
      "../clean_data/clean_dd_train/00000285.jpg\n",
      "../clean_data/clean_dd_train/00000130.jpg\n",
      "../clean_data/clean_dd_train/00000326.jpg\n",
      "../clean_data/clean_dd_train/00000332.jpg\n",
      "../clean_data/clean_dd_train/00000322.jpg\n",
      "../clean_data/clean_dd_train/00000134.jpg\n",
      "../clean_data/clean_dd_train/00000242.png\n",
      "../clean_data/clean_dd_train/00000281.jpg\n",
      "../clean_data/clean_dd_train/00000295.jpg\n",
      "../clean_data/clean_dd_train/00000294.jpg\n",
      "../clean_data/clean_dd_train/00000280.jpg\n",
      "../clean_data/clean_dd_train/00000135.jpg\n",
      "../clean_data/clean_dd_train/00000323.jpg\n",
      "../clean_data/clean_dd_train/00000337.jpg\n",
      "../clean_data/clean_dd_train/00000335.jpg\n",
      "../clean_data/clean_dd_train/00000309.jpg\n",
      "../clean_data/clean_dd_train/00000137.jpg\n",
      "../clean_data/clean_dd_train/00000241.jpg\n",
      "../clean_data/clean_dd_train/00000297.jpg\n",
      "../clean_data/clean_dd_train/00000268.jpg\n",
      "../clean_data/clean_dd_train/00000240.jpg\n",
      "../clean_data/clean_dd_train/00000254.jpg\n",
      "../clean_data/clean_dd_train/00000308.jpg\n",
      "../clean_data/clean_dd_train/00000334.jpg\n",
      "../clean_data/clean_dd_train/00000320.jpg\n",
      "../clean_data/clean_dd_train/00000409.jpg\n",
      "../clean_data/clean_dd_train/00000347.jpg\n",
      "../clean_data/clean_dd_train/00000186.png\n",
      "../clean_data/clean_dd_train/00000179.jpg\n",
      "../clean_data/clean_dd_train/00000145.jpg\n",
      "../clean_data/clean_dd_train/00000151.jpg\n",
      "../clean_data/clean_dd_train/00000233.jpg\n",
      "../clean_data/clean_dd_train/00000227.jpg\n",
      "../clean_data/clean_dd_train/00000232.jpg\n",
      "../clean_data/clean_dd_train/00000352.png\n",
      "../clean_data/clean_dd_train/00000187.jpg\n",
      "../clean_data/clean_dd_train/00000150.jpg\n",
      "../clean_data/clean_dd_train/00000144.jpg\n",
      "../clean_data/clean_dd_train/00000420.jpg\n",
      "../clean_data/clean_dd_train/00000346.jpg\n",
      "../clean_data/clean_dd_train/00000408.jpg\n",
      "../clean_data/clean_dd_train/00000378.jpg\n",
      "../clean_data/clean_dd_train/00000344.jpg\n",
      "../clean_data/clean_dd_train/00000422.jpg\n",
      "../clean_data/clean_dd_train/00000393.jpg\n",
      "../clean_data/clean_dd_train/00000152.jpg\n",
      "../clean_data/clean_dd_train/00000146.jpg\n",
      "../clean_data/clean_dd_train/00000224.jpg\n",
      "../clean_data/clean_dd_train/00000230.jpg\n",
      "../clean_data/clean_dd_train/00000225.jpg\n",
      "../clean_data/clean_dd_train/00000351.png\n",
      "../clean_data/clean_dd_train/00000379.png\n",
      "../clean_data/clean_dd_train/00000153.jpg\n",
      "../clean_data/clean_dd_train/00000392.jpg\n",
      "../clean_data/clean_dd_train/00000423.jpg\n",
      "../clean_data/clean_dd_train/00000341.jpg\n",
      "../clean_data/clean_dd_train/00000382.jpg\n",
      "../clean_data/clean_dd_train/00000143.jpg\n",
      "../clean_data/clean_dd_train/00000194.jpg\n",
      "../clean_data/clean_dd_train/00000180.jpg\n",
      "../clean_data/clean_dd_train/00000369.png\n",
      "../clean_data/clean_dd_train/00000221.jpg\n",
      "../clean_data/clean_dd_train/00000235.jpg\n",
      "../clean_data/clean_dd_train/00000209.jpg\n",
      "../clean_data/clean_dd_train/00000220.jpg\n",
      "../clean_data/clean_dd_train/00000142.jpg\n",
      "../clean_data/clean_dd_train/00000156.jpg\n",
      "../clean_data/clean_dd_train/00000426.jpg\n",
      "../clean_data/clean_dd_train/00000340.jpg\n",
      "../clean_data/clean_dd_train/00000354.jpg\n",
      "../clean_data/clean_dd_train/00000342.jpg\n",
      "../clean_data/clean_dd_train/00000140.jpg\n",
      "../clean_data/clean_dd_train/00000154.jpg\n",
      "../clean_data/clean_dd_train/00000183.jpg\n",
      "../clean_data/clean_dd_train/00000197.jpg\n",
      "../clean_data/clean_dd_train/00000222.jpg\n",
      "../clean_data/clean_dd_train/00000237.jpg\n",
      "../clean_data/clean_dd_train/00000155.jpg\n",
      "../clean_data/clean_dd_train/00000394.jpg\n",
      "../clean_data/clean_dd_train/00000419.jpg\n",
      "../clean_data/clean_dd_train/00000357.jpg\n",
      "../clean_data/clean_dd_train/00000343.jpg\n",
      "../clean_data/clean_dd_train/00000425.jpg\n"
     ]
    }
   ],
   "source": [
    "# Create DF of xyz values\n",
    "df = []\n",
    "\n",
    "for file in file_names:\n",
    "    dir_path_train_dd = f\"../clean_data/clean_dd_train/{file}\"\n",
    "    if not file.endswith((\".jpg\", \".png\")):\n",
    "        pass\n",
    "    else:\n",
    "        print(dir_path_train_dd)\n",
    "        image = tf.io.read_file(dir_path_train_dd)\n",
    "        image = tf.image.decode_jpeg(image)\n",
    "        input_image = tf.expand_dims(image, axis=0)\n",
    "        input_image = tf.image.resize_with_pad(input_image, input_size, input_size)\n",
    "        input_image = input_image[..., :3]\n",
    "\n",
    "        model = module.signatures[\"serving_default\"]\n",
    "        input_image = tf.cast(input_image, dtype=tf.int32)\n",
    "        outputs = model(input_image)\n",
    "        df.append(outputs[\"output_0\"].numpy().reshape(51).tolist())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.DataFrame(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()\n",
    "data[\"label\"] = \"downdog\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hathaproject",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
