{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "from tensorflow_docs.vis import embed\n",
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Import matplotlib libraries\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib.collections import LineCollection\n",
    "import matplotlib.patches as patches\n",
    "\n",
    "# Some modules to display an animation using imageio.\n",
    "import imageio\n",
    "from IPython.display import HTML, display\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Initialization\n",
    "model_name = \"movenet_lightning\"\n",
    "# module = hub.load(\"https://tfhub.dev/google/movenet/singlepose/lightning/4\")\n",
    "input_size = 192\n",
    "model = module.signatures['serving_default']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose image file and preprocess\n",
    "\n",
    "image_path = \"../clean_data/TRAIN/downdog/00000128.jpg\"\n",
    "image = tf.io.read_file(image_path)\n",
    "image = tf.image.decode_jpeg(image)\n",
    "\n",
    "# Resize and pad the image to keep the aspect ratio and fit the expected size.\n",
    "input_image = tf.expand_dims(image, axis=0)\n",
    "input_image = tf.image.resize_with_pad(input_image, input_size, input_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detect landmarks on image\n",
    "model = module.signatures[\"serving_default\"]\n",
    "input_image = tf.cast(input_image, dtype=tf.int32)\n",
    "input_image = input_image[..., :3]\n",
    "outputs = model(input_image)\n",
    "\n",
    "# 1D array of xyz coordinates. X1, Y1, Z1, X2, ... , Yn, Zn format\n",
    "xyz = outputs[\"output_0\"].numpy().reshape(51).tolist()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper method for drawing landmarks\n",
    "def draw_prediction_on_image(\n",
    "    image, keypoints_with_scores, crop_region=None, close_figure=False,\n",
    "    output_image_height=None):\n",
    "  \"\"\"Draws the keypoint predictions on image.\n",
    "\n",
    "  Args:\n",
    "    image: A numpy array with shape [height, width, channel] representing the\n",
    "      pixel values of the input image.\n",
    "    keypoints_with_scores: A numpy array with shape [1, 1, 17, 3] representing\n",
    "      the keypoint coordinates and scores returned from the MoveNet model.\n",
    "    crop_region: A dictionary that defines the coordinates of the bounding box\n",
    "      of the crop region in normalized coordinates (see the init_crop_region\n",
    "      function below for more detail). If provided, this function will also\n",
    "      draw the bounding box on the image.\n",
    "    output_image_height: An integer indicating the height of the output image.\n",
    "      Note that the image aspect ratio will be the same as the input image.\n",
    "\n",
    "  Returns:\n",
    "    A numpy array with shape [out_height, out_width, channel] representing the\n",
    "    image overlaid with keypoint predictions.\n",
    "  \"\"\"\n",
    "  height, width, channel = image.shape\n",
    "  aspect_ratio = float(width) / height\n",
    "  fig, ax = plt.subplots(figsize=(12 * aspect_ratio, 12))\n",
    "  # To remove the huge white borders\n",
    "  fig.tight_layout(pad=0)\n",
    "  ax.margins(0)\n",
    "  ax.set_yticklabels([])\n",
    "  ax.set_xticklabels([])\n",
    "  plt.axis('off')\n",
    "\n",
    "  im = ax.imshow(image)\n",
    "  line_segments = LineCollection([], linewidths=(4), linestyle='solid')\n",
    "  ax.add_collection(line_segments)\n",
    "  # Turn off tick labels\n",
    "  scat = ax.scatter([], [], s=60, color='#FF1493', zorder=3)\n",
    "\n",
    "  (keypoint_locs, keypoint_edges,\n",
    "   edge_colors) = _keypoints_and_edges_for_display(\n",
    "       keypoints_with_scores, height, width)\n",
    "\n",
    "  line_segments.set_segments(keypoint_edges)\n",
    "  line_segments.set_color(edge_colors)\n",
    "  if keypoint_edges.shape[0]:\n",
    "    line_segments.set_segments(keypoint_edges)\n",
    "    line_segments.set_color(edge_colors)\n",
    "  if keypoint_locs.shape[0]:\n",
    "    scat.set_offsets(keypoint_locs)\n",
    "\n",
    "  if crop_region is not None:\n",
    "    xmin = max(crop_region['x_min'] * width, 0.0)\n",
    "    ymin = max(crop_region['y_min'] * height, 0.0)\n",
    "    rec_width = min(crop_region['x_max'], 0.99) * width - xmin\n",
    "    rec_height = min(crop_region['y_max'], 0.99) * height - ymin\n",
    "    rect = patches.Rectangle(\n",
    "        (xmin,ymin),rec_width,rec_height,\n",
    "        linewidth=1,edgecolor='b',facecolor='none')\n",
    "    ax.add_patch(rect)\n",
    "\n",
    "  fig.canvas.draw()\n",
    "  image_from_plot = np.frombuffer(fig.canvas.tostring_rgb(), dtype=np.uint8)\n",
    "  image_from_plot = image_from_plot.reshape(\n",
    "      fig.canvas.get_width_height()[::-1] + (3,))\n",
    "  plt.close(fig)\n",
    "  if output_image_height is not None:\n",
    "    output_image_width = int(output_image_height / height * width)\n",
    "    image_from_plot = cv2.resize(\n",
    "        image_from_plot, dsize=(output_image_width, output_image_height),\n",
    "         interpolation=cv2.INTER_CUBIC)\n",
    "  return image_from_plot\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract landmarks from all files in a directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get list of image file names in given directory\n",
    "dir_path_train_dd = \"../clean_data/VAL/warrior2/warrior2_right\"\n",
    "file_names = []\n",
    "for entry in os.listdir(dir_path_train_dd):\n",
    "    file_names.append(entry)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../clean_data/VAL/warrior2/warrior2_right/00000010.jpg\n",
      "../clean_data/VAL/warrior2/warrior2_right/00000005.jpg\n",
      "../clean_data/VAL/warrior2/warrior2_right/00000011.jpg\n",
      "../clean_data/VAL/warrior2/warrior2_right/00000006.png\n",
      "../clean_data/VAL/warrior2/warrior2_right/00000016.jpg\n",
      "../clean_data/VAL/warrior2/warrior2_right/00000015.jpg\n",
      "../clean_data/VAL/warrior2/warrior2_right/00000000.jpg\n",
      "../clean_data/VAL/warrior2/warrior2_right/00000040.jpg\n",
      "../clean_data/VAL/warrior2/warrior2_right/00000018.jpg\n",
      "../clean_data/VAL/warrior2/warrior2_right/00000032.jpg\n",
      "../clean_data/VAL/warrior2/warrior2_right/00000033.jpg\n",
      "../clean_data/VAL/warrior2/warrior2_right/00000034.jpg\n",
      "../clean_data/VAL/warrior2/warrior2_right/00000020.jpg\n",
      "../clean_data/VAL/warrior2/warrior2_right/00000035.jpg\n"
     ]
    }
   ],
   "source": [
    "# Create DF of xyz values\n",
    "df = []\n",
    "xyz = []\n",
    "for file in file_names:\n",
    "    dir_path_train_dd = f\"../clean_data/VAL/warrior2/warrior2_right/{file}\"\n",
    "    if not file.endswith((\".jpg\", \".png\")):\n",
    "        pass\n",
    "    else:\n",
    "        print(dir_path_train_dd)\n",
    "        image = tf.io.read_file(dir_path_train_dd)\n",
    "        image = tf.image.decode_jpeg(image)\n",
    "        input_image = tf.expand_dims(image, axis=0)\n",
    "        input_image = tf.image.resize_with_pad(input_image, input_size, input_size)\n",
    "        input_image = input_image[..., :3]\n",
    "\n",
    "        model = module.signatures[\"serving_default\"]\n",
    "        input_image = tf.cast(input_image, dtype=tf.int32)\n",
    "        outputs = model(input_image)\n",
    "        to_df = outputs[\"output_0\"].numpy().reshape(51).tolist()\n",
    "        to_df.insert(0, dir_path_train_dd)\n",
    "        df.append(to_df)\n",
    "\n",
    "        # Append the unflattened data for angle analysis\n",
    "        # xyz.append(outputs[\"output_0\"].numpy()[0][0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"movenet_lightning\"\n",
    "module = hub.load(\"https://tfhub.dev/google/movenet/singlepose/lightning/4\")\n",
    "\n",
    "def get_xyz(file_path, module):\n",
    "    \"\"\"\n",
    "    This function takes a filepath for an image, and returns a list of xyz\n",
    "    coordinates of the landmarks\n",
    "    \"\"\"\n",
    "    input_size = 192\n",
    "\n",
    "    image = tf.io.read_file(file_path)\n",
    "    image = tf.image.decode_jpeg(image)\n",
    "    input_image = tf.expand_dims(image, axis=0)\n",
    "    input_image = tf.image.resize_with_pad(input_image, input_size, input_size)\n",
    "    input_image = input_image[..., :3]\n",
    "    input_image = tf.cast(input_image, dtype=tf.int32)\n",
    "\n",
    "    model = module.signatures[\"serving_default\"]\n",
    "    outputs = model(input_image)\n",
    "\n",
    "    xyz = outputs[\"output_0\"].numpy()\n",
    "\n",
    "    return xyz\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change to DataFrame\n",
    "a = pd.DataFrame(df)\n",
    "\n",
    "# Add extra y1 and y2 labels\n",
    "a[\"y_main\"] =  \"warrior2\"\n",
    "a[\"y_sub\"] = \"warrior2_right\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the below just once when creating test_landmark_all for the first time\n",
    "# val_landmark_all = a\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(144, 54)"
      ]
     },
     "execution_count": 245,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_landmark_all = pd.concat([val_landmark_all, a], ignore_index=True)\n",
    "val_landmark_all.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>44</th>\n",
       "      <th>45</th>\n",
       "      <th>46</th>\n",
       "      <th>47</th>\n",
       "      <th>48</th>\n",
       "      <th>49</th>\n",
       "      <th>50</th>\n",
       "      <th>51</th>\n",
       "      <th>y_main</th>\n",
       "      <th>y_sub</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>139</th>\n",
       "      <td>../clean_data/VAL/warrior2/warrior2_right/0000...</td>\n",
       "      <td>0.318528</td>\n",
       "      <td>0.554444</td>\n",
       "      <td>0.733416</td>\n",
       "      <td>0.306447</td>\n",
       "      <td>0.540627</td>\n",
       "      <td>0.627944</td>\n",
       "      <td>0.304539</td>\n",
       "      <td>0.550032</td>\n",
       "      <td>0.782912</td>\n",
       "      <td>...</td>\n",
       "      <td>0.679014</td>\n",
       "      <td>0.485207</td>\n",
       "      <td>0.755016</td>\n",
       "      <td>0.242915</td>\n",
       "      <td>0.634383</td>\n",
       "      <td>0.753780</td>\n",
       "      <td>0.680964</td>\n",
       "      <td>0.787631</td>\n",
       "      <td>warrior2</td>\n",
       "      <td>warrior2_right</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>../clean_data/VAL/warrior2/warrior2_right/0000...</td>\n",
       "      <td>0.312817</td>\n",
       "      <td>0.576883</td>\n",
       "      <td>0.735261</td>\n",
       "      <td>0.295354</td>\n",
       "      <td>0.562783</td>\n",
       "      <td>0.694497</td>\n",
       "      <td>0.291925</td>\n",
       "      <td>0.563010</td>\n",
       "      <td>0.623199</td>\n",
       "      <td>...</td>\n",
       "      <td>0.719067</td>\n",
       "      <td>0.770251</td>\n",
       "      <td>0.835029</td>\n",
       "      <td>0.160283</td>\n",
       "      <td>0.785591</td>\n",
       "      <td>0.829874</td>\n",
       "      <td>0.747690</td>\n",
       "      <td>0.856841</td>\n",
       "      <td>warrior2</td>\n",
       "      <td>warrior2_right</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141</th>\n",
       "      <td>../clean_data/VAL/warrior2/warrior2_right/0000...</td>\n",
       "      <td>0.295378</td>\n",
       "      <td>0.429856</td>\n",
       "      <td>0.718781</td>\n",
       "      <td>0.282970</td>\n",
       "      <td>0.429444</td>\n",
       "      <td>0.850737</td>\n",
       "      <td>0.282381</td>\n",
       "      <td>0.418199</td>\n",
       "      <td>0.748058</td>\n",
       "      <td>...</td>\n",
       "      <td>0.237722</td>\n",
       "      <td>0.730614</td>\n",
       "      <td>0.723085</td>\n",
       "      <td>0.530338</td>\n",
       "      <td>0.596994</td>\n",
       "      <td>0.703935</td>\n",
       "      <td>0.135520</td>\n",
       "      <td>0.728457</td>\n",
       "      <td>warrior2</td>\n",
       "      <td>warrior2_right</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142</th>\n",
       "      <td>../clean_data/VAL/warrior2/warrior2_right/0000...</td>\n",
       "      <td>0.256058</td>\n",
       "      <td>0.591267</td>\n",
       "      <td>0.738903</td>\n",
       "      <td>0.239507</td>\n",
       "      <td>0.578456</td>\n",
       "      <td>0.635123</td>\n",
       "      <td>0.238964</td>\n",
       "      <td>0.574713</td>\n",
       "      <td>0.690047</td>\n",
       "      <td>...</td>\n",
       "      <td>0.283504</td>\n",
       "      <td>0.860723</td>\n",
       "      <td>0.797230</td>\n",
       "      <td>0.731032</td>\n",
       "      <td>0.826005</td>\n",
       "      <td>0.808969</td>\n",
       "      <td>0.099310</td>\n",
       "      <td>0.839227</td>\n",
       "      <td>warrior2</td>\n",
       "      <td>warrior2_right</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143</th>\n",
       "      <td>../clean_data/VAL/warrior2/warrior2_right/0000...</td>\n",
       "      <td>0.293906</td>\n",
       "      <td>0.580950</td>\n",
       "      <td>0.300048</td>\n",
       "      <td>0.274271</td>\n",
       "      <td>0.572011</td>\n",
       "      <td>0.388846</td>\n",
       "      <td>0.275559</td>\n",
       "      <td>0.581232</td>\n",
       "      <td>0.488962</td>\n",
       "      <td>...</td>\n",
       "      <td>0.765567</td>\n",
       "      <td>0.620287</td>\n",
       "      <td>0.828237</td>\n",
       "      <td>0.245025</td>\n",
       "      <td>0.553020</td>\n",
       "      <td>0.857876</td>\n",
       "      <td>0.786115</td>\n",
       "      <td>0.771510</td>\n",
       "      <td>warrior2</td>\n",
       "      <td>warrior2_right</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 54 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     0         1         2  \\\n",
       "139  ../clean_data/VAL/warrior2/warrior2_right/0000...  0.318528  0.554444   \n",
       "140  ../clean_data/VAL/warrior2/warrior2_right/0000...  0.312817  0.576883   \n",
       "141  ../clean_data/VAL/warrior2/warrior2_right/0000...  0.295378  0.429856   \n",
       "142  ../clean_data/VAL/warrior2/warrior2_right/0000...  0.256058  0.591267   \n",
       "143  ../clean_data/VAL/warrior2/warrior2_right/0000...  0.293906  0.580950   \n",
       "\n",
       "            3         4         5         6         7         8         9  \\\n",
       "139  0.733416  0.306447  0.540627  0.627944  0.304539  0.550032  0.782912   \n",
       "140  0.735261  0.295354  0.562783  0.694497  0.291925  0.563010  0.623199   \n",
       "141  0.718781  0.282970  0.429444  0.850737  0.282381  0.418199  0.748058   \n",
       "142  0.738903  0.239507  0.578456  0.635123  0.238964  0.574713  0.690047   \n",
       "143  0.300048  0.274271  0.572011  0.388846  0.275559  0.581232  0.488962   \n",
       "\n",
       "     ...        44        45        46        47        48        49  \\\n",
       "139  ...  0.679014  0.485207  0.755016  0.242915  0.634383  0.753780   \n",
       "140  ...  0.719067  0.770251  0.835029  0.160283  0.785591  0.829874   \n",
       "141  ...  0.237722  0.730614  0.723085  0.530338  0.596994  0.703935   \n",
       "142  ...  0.283504  0.860723  0.797230  0.731032  0.826005  0.808969   \n",
       "143  ...  0.765567  0.620287  0.828237  0.245025  0.553020  0.857876   \n",
       "\n",
       "           50        51    y_main           y_sub  \n",
       "139  0.680964  0.787631  warrior2  warrior2_right  \n",
       "140  0.747690  0.856841  warrior2  warrior2_right  \n",
       "141  0.135520  0.728457  warrior2  warrior2_right  \n",
       "142  0.099310  0.839227  warrior2  warrior2_right  \n",
       "143  0.786115  0.771510  warrior2  warrior2_right  \n",
       "\n",
       "[5 rows x 54 columns]"
      ]
     },
     "execution_count": 246,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_landmark_all.tail()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_dict = {i: f\"{chr(88 + (i-1) % 3)}{1 + (i-1) // 3}\" for i in range(1, 52)}\n",
    "col_dict\n",
    "val_landmark_all.rename(columns=col_dict, inplace=True)\n",
    "val_landmark_all.rename(columns={0: \"file_path\"}, inplace=True)\n",
    "\n",
    "val_landmark_all.to_csv(\"val_landmark_all_raw.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hathaproject",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
